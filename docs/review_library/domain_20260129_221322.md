# Domain Correctness & Compliance Review - KMI Manager CLI
Date: 2026-01-29

## Reviewer Profile
I bring 30 years of experience building and operating developer platforms, API gateways, and regulated fintech workflows where key custody, rotation, and auditability are mandatory. Over that time I have designed rotation and rate-limiting policies for both security (key lifecycle) and reliability (traffic shaping), and have helped teams pass vendor and regulatory compliance reviews. I focus on how operational guardrails and defaults steer behavior as much as the core logic does. My goal here is to surface where the implementation could drift from provider ToS or internal policy even if the code works as intended.

## Scope and Evidence
- Key rotation logic: `src/kmi_manager_cli/rotation.py`
- Proxy routing and auth: `src/kmi_manager_cli/proxy.py`
- Health and usage scoring: `src/kmi_manager_cli/health.py`
- Key registry and account loading: `src/kmi_manager_cli/keys.py`, `src/kmi_manager_cli/auth_accounts.py`
- Config and policy toggles: `src/kmi_manager_cli/config.py`, `src/kmi_manager_cli/cli.py`, `src/kmi_manager_cli/errors.py`
- State, logs, and trace: `src/kmi_manager_cli/state.py`, `src/kmi_manager_cli/trace.py`, `src/kmi_manager_cli/logging.py`, `src/kmi_manager_cli/ui.py`

## Executive Summary
The project implements round-robin and manual rotation consistent with the stated requirements and includes basic ToS warnings, local-only defaults, and optional rate limits. The primary compliance risks are policy enforcement (pooling across accounts without guardrails), default behaviors that can silently enable auto-rotation, and logging/trace handling that may expose sensitive metadata. Operational workflows are workable but lack explicit disablement, permission checks, and strong audit or retention controls. Addressing these gaps will reduce ToS exposure and make the tool safer to operate in regulated or shared environments.

## Findings

### API Key Rotation Policy Correctness
- Implemented rotation matches the intended round-robin selection and skip logic for unhealthy keys, and respects a global auto-rotation allow flag. `src/kmi_manager_cli/rotation.py`, `src/kmi_manager_cli/proxy.py`, `src/kmi_manager_cli/config.py`.
- 403 handling is inconsistent with a cooldown policy: proxy marks 403 as exhausted, but rotation permanently blocks any key that has ever seen a 403 because `_is_eligible` rejects `error_403 > 0`. This can permanently remove keys that are temporarily restricted, undermining the cooldown model. `src/kmi_manager_cli/proxy.py`, `src/kmi_manager_cli/rotation.py`, `src/kmi_manager_cli/health.py`.
- Usage fetch failures (network or auth) return `None` and are scored as `warn`, which still keeps keys eligible for manual rotation. This can select invalid keys until a failed proxy request records a 401/403. `src/kmi_manager_cli/health.py`, `src/kmi_manager_cli/rotation.py`.
- The registry allows pooling keys from different accounts and providers without validation. There is no policy boundary or allowlist to ensure keys belong to the same org/tenant, which is typically required for compliant pooling. `src/kmi_manager_cli/keys.py`, `src/kmi_manager_cli/auth_accounts.py`.
- Rotation is request-level load balancing, not security key rotation (issuance/revocation). If the product goal includes periodic key replacement, there is no lifecycle workflow for reissuing or retiring keys. This should be documented or expanded.

### ToS / SLA Compliance Considerations
- The CLI warns about provider ToS and supports an `auto_rotate_allowed` policy flag, which is good. However, the default allows auto-rotation and the state persists once enabled, meaning a prior enablement silently reactivates on future proxy runs. There is no explicit disable command. `src/kmi_manager_cli/config.py`, `src/kmi_manager_cli/cli.py`, `src/kmi_manager_cli/state.py`.
- Remote binding requires explicit opt-in and a proxy token, which is a compliance-friendly guardrail. `src/kmi_manager_cli/proxy.py`.
- The proxy forwards all headers except `Host` and `Content-Length`, so `x-kmi-proxy-token` (or other internal auth headers) are forwarded upstream. This risks leaking internal access tokens to the upstream provider and should be stripped. `src/kmi_manager_cli/proxy.py`.
- Logs and trace files are stored in plaintext under `~/.kmi/` and include key labels, request paths, and key hashes. Health dashboards can display account email addresses. This may violate internal data handling policies without explicit retention/redaction controls or file permission checks. `src/kmi_manager_cli/trace.py`, `src/kmi_manager_cli/logging.py`, `src/kmi_manager_cli/ui.py`.
- Rate limiting is proxy-wide, not per-key. With multiple clients or high concurrency, traffic can exceed per-key quotas even with round-robin selection, which can be non-compliant with provider limits. `src/kmi_manager_cli/proxy.py`.

### Operational Workflow Observations
- Workflows are clear: keys load from `_auths` and `~/.kimi/config.toml`, manual rotation uses health, auto-rotation toggles a persistent state flag, proxy performs per-request selection, and trace/health dashboards read local JSONL and usage data. `src/kmi_manager_cli/cli.py`, `src/kmi_manager_cli/trace.py`, `src/kmi_manager_cli/health.py`.
- `KMI_DRY_RUN` defaults to true. In dry-run, usage is mocked and requests are not sent upstream, which can mislead operators into believing rotation or quotas are validated when they are not. This is safe for testing but should be very explicit in operational documentation. `src/kmi_manager_cli/config.py`, `src/kmi_manager_cli/health.py`, `src/kmi_manager_cli/proxy.py`.
- State is persisted with file locking and atomic writes, but is loaded once at startup and then mutated in memory. Running multiple proxies or mixing CLI/proxy concurrently can diverge state and produce non-deterministic rotation, potentially spiking request rates on a single key. `src/kmi_manager_cli/state.py`, `src/kmi_manager_cli/proxy.py`.

## Recommendations (Prioritized)
1. Add explicit compliance gating: require an explicit opt-in flag for auto-rotation (for example `KMI_AUTO_ROTATE_ALLOWED=1` plus a dedicated enable flag) and provide a `kmi rotate off` command to disable the persisted state.
2. Introduce pool boundary controls: allowlist base URLs or account emails and optionally enforce “single org/tenant” rules before keys are eligible for auto-rotation.
3. Align 403 handling with policy: distinguish permanent auth failures from temporary policy/rate errors; use cooldown for temporary 403s and only permanently block when the error is definitively auth-related.
4. Improve health signal fidelity: detect auth failures during `/usages` fetch and mark keys blocked; treat usage fetch errors as “unknown” and exclude from automatic selection unless explicitly allowed.
5. Strip internal proxy auth headers before forwarding upstream (at minimum `x-kmi-proxy-token`) and add a redaction/retention strategy for logs and trace.
6. Add per-key rate limiting or concurrency caps to better honor provider rate limits and avoid accidental ToS violations under load.
7. Add file permission checks for `_auths` and `~/.kimi/config.toml` and warn if files are world-readable.
8. Document the operational runbook: how to enable/disable auto-rotation, how to interpret dry-run, and how to rotate keys as a security lifecycle (issue/revoke/retire).

## Open Questions
- Should 403 always imply permanent block for this provider, or is it sometimes a temporary quota/feature restriction that should be handled via cooldown?
- Is pooling across multiple accounts an intended feature, and if so, is there a requirement to prove common ownership (for example by matching account email or org ID)?
- Do you need a formal audit log or retention policy for trace/log files (for example, rolling logs, encryption at rest, or a purge schedule)?
